---
title: 'Nemotron Orchestrator 8B'
description: '> An orchestration-focused model designed to coordinate tools and multiple models for complex, multi-turn agent workflows.'
---

## About the Provider
NVIDIA is a global leader in AI computing and accelerated hardware, known for its GPUs and enterprise AI platforms. Through its NeMo and research initiatives, NVIDIA develops models like Nemotron Orchestrator to enable advanced reasoning, tool orchestration, and scalable AI workflows for developers and enterprises.

## Model Quickstart

This section helps you quickly get started with the `nvidia/Orchestrator-8B` model on the Qubrid AI inferencing platform.

To use this model, you need:
- A valid **Qubrid API key**
- Access to the Qubrid inference API
- Basic knowledge of making API requests in your preferred language

Once authenticated with your API key, you can send inference requests to the `nvidia/Orchestrator-8B` model and receive responses based on your input prompts.

Below are example placeholders showing how the model can be accessed using different programming environments.  
You can choose the one that best fits your workflow.

<CodeGroup>
  ```python Python theme={null}
import requests
import json
from pprint import pprint

url = "https://platform.qubrid.com/api/v1/qubridai/chat/completions"

headers = {
    "Authorization": "Bearer <QUBRID_API_KEY>",
    "Content-Type": "application/json"
}
data = {
    "model": "nvidia/Orchestrator-8B",
    "messages": [
        {
            "role": "user",
            "content": "Explain quantum computing to a 5 year old."
        }
    ],
    "temperature": 0.7,
    "max_tokens": 4096,   
    "stream": True,
    "top_p": 0.8
}
response = requests.post(
    url,
    headers=headers,
    json=data, 
)
content_type = response.headers.get("Content-Type", "")
if "application/json" in content_type:
    pprint(response.json())
else:
    for line in response.iter_lines(decode_unicode=True):
        if not line:
            continue
        if line.startswith("data:"):
            payload = line.replace("data:", "").strip()
            if payload == "[DONE]":
                break
            try:
                chunk = json.loads(payload)
                pprint(chunk)
            except json.JSONDecodeError:
                print("Raw chunk:", payload)
````

```js JavaScript theme={null}
(async () => {
  const body = {
    model: "nvidia/Orchestrator-8B",
    messages: [
      {
        role: "user",
        content: "Explain quantum computing to a 5 year old.",
      },
    ],
    temperature: 0.8,
    max_tokens: 4096,
    stream: true,
    top_p: 0.8,
  };

  const res = await fetch(
    "https://platform.qubrid.com/api/v1/qubridai/chat/completions",
    {
      method: "POST",
      headers: {
        Authorization:
          "Bearer <QUBRID_API_KEY>",
        "Content-Type": "application/json",
      },
      body: JSON.stringify(body),
    }
  );

  const contentType = res.headers.get("content-type") || "";
  if (contentType.includes("application/json")) {
    const result = await res.json();
    console.log(result);
  } else {
    const reader = res.body.getReader();
    const decoder = new TextDecoder("utf-8");
    let buffer = "";
    while (true) {
      const { value, done } = await reader.read();
      if (done) break;
      buffer += decoder.decode(value, { stream: true });
      const lines = buffer.split("\n");
      buffer = lines.pop();
      for (const line of lines) {
        if (!line.startsWith("data:")) continue;
        const payload = line.replace("data:", "").trim();
        if (payload === "[DONE]") return;
        try {
          const chunk = JSON.parse(payload);
          console.log(chunk);
        } catch {
          console.log("Raw chunk:", payload);
        }
      }
    }
  }
})();
````

```go Go theme={null}
package main

import (
	"bytes"
	"bufio"
	"encoding/json"
	"fmt"
	"net/http"
	"strings"
)

func main() {
	url := "https://platform.qubrid.com/api/v1/qubridai/chat/completions"

	data := map[string]interface{}{
		"model": "nvidia/Orchestrator-8B",
		"messages": []map[string]string{
			{
				"role":    "user",
				"content": "Explain quantum computing in simple terms",
			},
		},
		"temperature": 0.7,
		"max_tokens":  4096,
		"stream":  false,
		"top_p":       1,
	}

    jsonData, err := json.Marshal(data)
    if err != nil {
		panic(err)
	}

	req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
	if err != nil {
		panic(err)
	}

	req.Header.Set("Authorization", "Bearer <QUBRID_API_KEY>")
	req.Header.Set("Content-Type", "application/json")

	client := &http.Client{}
	res, err := client.Do(req)
	if err != nil {
		panic(err)
	}
	defer res.Body.Close()
	contentType := res.Header.Get("Content-Type")
	if strings.Contains(contentType, "application/json") {
		var result map[string]interface{}
		if err := json.NewDecoder(res.Body).Decode(&result); err != nil {
			panic(err)
		}
		fmt.Printf("%+v\n", result)
		return
	}
	scanner := bufio.NewScanner(res.Body)
	for scanner.Scan() {
		line := scanner.Text()
		if !strings.HasPrefix(line, "data:") {
			continue
		}
		payload := strings.TrimSpace(strings.TrimPrefix(line, "data:"))
		if payload == "[DONE]" {
			break
		}
		var chunk map[string]interface{}
		if err := json.Unmarshal([]byte(payload), &chunk); err != nil {
			fmt.Println("Raw chunk:", payload)
			continue
		}
		fmt.Printf("%+v\n", chunk)
	}
	if err := scanner.Err(); err != nil {
		panic(err)
	}
}
```

```curl cURL theme={null}
curl -X POST "https://platform.qubrid.com/api/v1/qubridai/chat/completions" \
  -H "Authorization: Bearer <QUBRID_API_KEY>" \
  -H "Content-Type: application/json" \
  -d '{
  "model": "nvidia/Orchestrator-8B",
  "messages": [
    {
      "role": "user",
      "content": "Explain quantum computing in simple terms"
    }
  ],
  "temperature": 0.7,
  "max_tokens": 4096,
  "stream":false
}'
```
</CodeGroup>

## Model Overview

**Nemotron Orchestrator 8B** is a state-of-the-art 8B parameter orchestration model designed to solve complex, multi-turn agentic tasks.
It works by coordinating a diverse set of expert models and tools rather than acting as a single monolithic model.

On the Humanity’s Last Exam (HLE) benchmark, Orchestrator-8B achieves a score of 37.1%, outperforming GPT-5 (35.1%) while being approximately 2.5× more efficient.

### Model at a Glance
| Feature | Details |
|---------|---------|
| Model ID | `nvidia/Orchestrator-8B` |
| Provider | NVIDIA |
| Architecture | Optimized Transformer (TensorRT-LLM enhanced) |
| Context Length | 16384 Tokens |
| Model Size | 7B params |
|Parameters | 4 |
| Training Data | Orchestration datasets, workflow sequences, tool-use datasets, enterprise task simulations |
|Base Model | Qwen3-8B |

### When to use?

You should consider using **Nemotron Orchestrator 8B** if::

- You are working on complex, multi-turn agentic tasks
- You need a model that can coordinate multiple tools and expert models
- You want higher accuracy at lower computational cost
- You are conducting research or development focused on orchestration and reasoning
- You plan to fine-tune the model for specific tasks
- You need a model that can generalize to unseen tools and pricing setups

### Inference Parameters
| Parameter Name | Type    | Default | Description                                                                 |
|----------------|---------|---------|-----------------------------------------------------------------------------|
| Streaming      | boolean | true    | Enable streaming responses for real-time output.                            |
| Temperature    | number  | 0.4     | Controls creativity and randomness; lower values are recommended for deterministic tasks. |
| Max Tokens     | number  | 4096    | Maximum number of tokens the model can generate.                            |
| Top P          | number  | 1       | Controls nucleus sampling for more predictable output.                     |

### Key Features
- **Intelligent Orchestration**
Capable of managing heterogeneous toolsets, including basic tools such as search and code execution, as well as other LLMs (both specialized and generalist).
- **Efficiency**
Delivers higher accuracy at significantly lower computational cost compared to monolithic frontier models
- **Robust Generalization**
Demonstrates the ability to generalize to unseen tools and pricing configurations.

### Benchmark Performance
- Achieves 37.1% on the Humanity’s Last Exam (HLE) benchmark
- Outperforms:GPT-5 , Claude Opus 4.1 , Qwen3-235B-A22B

### Limitations
- **Scalability**
The model has not been tested at larger sizes (greater than 8B parameters), and it is unclear whether performance and efficiency advantages would persist at that scale.

- **Coverage:** 
The model has not been evaluated across broader domains such as code generation or web interaction, so its generalization beyond the studied reasoning tasks remains unverified.

## Summary
**Nemotron Orchestrator 8B** is a state-of-the-art 8B parameter orchestration model designed for complex, multi-turn agentic tasks.
- It coordinates multiple expert models and tools to solve problems efficiently.
- On the Humanity’s Last Exam benchmark, it outperforms GPT-5 while being approximately 2.5× more efficient.
- The model delivers higher accuracy at lower computational cost than monolithic frontier models.
- It is intended for research and development use only.

